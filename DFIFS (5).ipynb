{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NRgR6f-8vfp",
        "outputId": "020ec8bd-e956-454f-be2a-43c523715915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap==0.44.0\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (2.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (4.66.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (24.0)\n",
            "Collecting slicer==0.0.7 (from shap==0.44.0)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap==0.44.0) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap==0.44.0) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap==0.44.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap==0.44.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap==0.44.0) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap==0.44.0) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap==0.44.0) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap==0.44.0) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install shap==0.44.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuVpm8EK8x_s",
        "outputId": "49b5d64d-6919-4c1d-c7ac-58e16df9349f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrmr_selection\n",
            "  Downloading mrmr_selection-0.2.8-py3-none-any.whl (15 kB)\n",
            "Collecting category-encoders (from mrmr_selection)\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (3.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (4.66.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (1.4.0)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (1.11.4)\n",
            "Requirement already satisfied: polars>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from mrmr_selection) (0.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->mrmr_selection) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->mrmr_selection) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->mrmr_selection) (2024.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders->mrmr_selection) (0.14.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders->mrmr_selection) (0.5.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mrmr_selection) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mrmr_selection) (2.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders->mrmr_selection) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category-encoders->mrmr_selection) (24.0)\n",
            "Installing collected packages: category-encoders, mrmr_selection\n",
            "Successfully installed category-encoders-2.6.3 mrmr_selection-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install mrmr_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MImtfx8w80tp",
        "outputId": "0568583a-2172-4130-b58d-ef7447913d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting minepy\n",
            "  Downloading minepy-1.2.6.tar.gz (496 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/497.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/497.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m491.5/497.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.0/497.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from minepy) (1.25.2)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.6-cp310-cp310-linux_x86_64.whl size=187102 sha256=c2c18acb1083fcca77e5d5f8f6df93fd84aeb3a625675f9e04b669b6914e6638\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/38/a6/825bb9b9ed81e6af43a0ef80c7cfe4cafcfdbc2f5cde2959d9\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install minepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nDsnYBL84-A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import mrmr\n",
        "from minepy import MINE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mrmr import mrmr_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Adksqty9aIO"
      },
      "source": [
        "# ***mRmR feature selection***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPdCJ95H9YfI",
        "outputId": "92796ea6-dcf8-4453-c7c0-eebb270a05c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 252.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 243.19it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 220.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 304.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 226.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 170.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 212.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 362.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 325.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 250.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0       1       2       3       4       5       6      7       8  \\\n",
            "3    138.0   165.0   209.0   338.0   196.0   334.0   442.0   95.2    43.3   \n",
            "17   185.0   112.0   194.0   194.0   199.0    49.0    36.4   51.8   286.0   \n",
            "48  1930.0   328.0   558.0   481.0   645.0   992.0  2640.0   83.9   422.0   \n",
            "8   3890.0  1780.0  1850.0   598.0  1730.0   542.0  1250.0   54.2    28.9   \n",
            "6   2030.0  1390.0  1450.0   387.0  1470.0   325.0   453.0   77.2    79.7   \n",
            "33   287.0   265.0   436.0   147.0   443.0    43.6    59.0  147.0   327.0   \n",
            "4    988.0   723.0   577.0   661.0   598.0   973.0  1330.0   36.3   393.0   \n",
            "46   868.0   288.0   453.0   443.0   606.0   103.0   584.0  334.0  1280.0   \n",
            "19   231.0   125.0   179.0   229.0   156.0    51.8    65.8  115.0   735.0   \n",
            "53   660.0   184.0   393.0   217.0   393.0    76.7   608.0  115.0   835.0   \n",
            "41   336.0    85.0   197.0    93.1   181.0   183.0   816.0   56.4   886.0   \n",
            "54  3130.0   935.0  2310.0   581.0  2310.0  1340.0  4070.0   13.7   646.0   \n",
            "31   471.0   567.0   739.0   261.0   766.0   665.0  1190.0  323.0   380.0   \n",
            "30   413.0   394.0   598.0   241.0   582.0   216.0   248.0  306.0   730.0   \n",
            "58   175.0    42.7   134.0   115.0   127.0    88.6   690.0  117.0   834.0   \n",
            "59   966.0   147.0   377.0   239.0   443.0    83.5   630.0  102.0  2350.0   \n",
            "15   636.0   543.0   633.0   450.0   660.0   282.0   421.0  116.0   456.0   \n",
            "27   340.0   237.0   349.0   144.0   344.0   138.0   434.0  102.0   421.0   \n",
            "26   103.0   106.0   150.0   103.0   149.0    85.4   628.0  110.0  1190.0   \n",
            "24   164.0   141.0   213.0   229.0   209.0    69.1   108.0   13.0    48.8   \n",
            "45  2520.0   749.0  1810.0  1050.0  1780.0  1490.0  2900.0  134.0   809.0   \n",
            "11   416.0   333.0   335.0   365.0   353.0    61.5   168.0  540.0   997.0   \n",
            "32   813.0   306.0   663.0   176.0   562.0   111.0   230.0  278.0   190.0   \n",
            "56  2790.0   734.0  1750.0   372.0  1890.0   697.0  2060.0   32.8   182.0   \n",
            "44   847.0   276.0   541.0   303.0   736.0   228.0   673.0  274.0  1180.0   \n",
            "37   250.0   181.0   362.0   280.0   353.0   402.0   286.0  199.0   886.0   \n",
            "29   448.0   282.0   474.0   286.0   448.0   413.0   474.0  340.0  1520.0   \n",
            "47   687.0   182.0   657.0   170.0   586.0    99.6  1320.0  193.0  1740.0   \n",
            "1    553.0   390.0   475.0   624.0   471.0   309.0   561.0  137.0   631.0   \n",
            "21   188.0   185.0   272.0   490.0   246.0    81.3   105.0  247.0  1170.0   \n",
            "2   2310.0  1780.0  1650.0  1340.0  1710.0  1640.0  4420.0   78.2   859.0   \n",
            "50  4640.0  1060.0  2570.0  1780.0  2610.0  2200.0  3830.0   35.4   311.0   \n",
            "39  2690.0  1110.0  1720.0   437.0  1880.0  1210.0  3410.0   24.5   228.0   \n",
            "35   506.0   287.0   365.0   214.0   378.0   182.0   357.0  124.0   685.0   \n",
            "23   182.0    93.3   118.0    79.3   133.0    16.0    91.5   16.2   409.0   \n",
            "52  1080.0   339.0   527.0   357.0   636.0    21.1   735.0  146.0   693.0   \n",
            "10  4320.0  2510.0  2510.0   906.0  2550.0   774.0  1770.0   51.2   193.0   \n",
            "22  2420.0  1390.0  1510.0  1270.0  1770.0  1220.0  1850.0  107.0   311.0   \n",
            "18   412.0   258.0   373.0   620.0   378.0    89.8   127.0   45.5    83.9   \n",
            "62  2700.0   549.0  1240.0   596.0  1160.0   954.0  1880.0   51.9   129.0   \n",
            "20  3030.0  1560.0  1610.0   760.0  1510.0   297.0   538.0   57.8    87.5   \n",
            "7    228.0   154.0   215.0   150.0   199.0   126.0   144.0   99.3   402.0   \n",
            "42  1770.0   449.0  1260.0   543.0  1290.0   480.0  1640.0   64.0   439.0   \n",
            "14  1870.0  1490.0  1420.0  1230.0  1480.0  1240.0  1400.0   23.4   236.0   \n",
            "28   330.0   216.0   290.0   255.0   314.0   179.0   410.0  241.0  1700.0   \n",
            "51   754.0    85.1   212.0   361.0   195.0    55.2   252.0  118.0   400.0   \n",
            "38   228.0   220.0   283.0    92.3   306.0    51.1    78.6   84.5   743.0   \n",
            "\n",
            "         9  \n",
            "3    233.0  \n",
            "17   525.0  \n",
            "48   374.0  \n",
            "8    132.0  \n",
            "6    148.0  \n",
            "33  1050.0  \n",
            "4    371.0  \n",
            "46  1720.0  \n",
            "19   378.0  \n",
            "53   734.0  \n",
            "41   420.0  \n",
            "54   184.0  \n",
            "31   948.0  \n",
            "30  2500.0  \n",
            "58   313.0  \n",
            "59  1040.0  \n",
            "15   242.0  \n",
            "27   871.0  \n",
            "26   672.0  \n",
            "24    49.8  \n",
            "45   665.0  \n",
            "11  1740.0  \n",
            "32   623.0  \n",
            "56   312.0  \n",
            "44  2370.0  \n",
            "37   310.0  \n",
            "29  1730.0  \n",
            "47   710.0  \n",
            "1    510.0  \n",
            "21   742.0  \n",
            "2    568.0  \n",
            "50   371.0  \n",
            "39   147.0  \n",
            "35   533.0  \n",
            "23   298.0  \n",
            "52  1800.0  \n",
            "10   131.0  \n",
            "22   227.0  \n",
            "18   139.0  \n",
            "62   477.0  \n",
            "20   146.0  \n",
            "7    610.0  \n",
            "42   268.0  \n",
            "14   157.0  \n",
            "28  1360.0  \n",
            "51   649.0  \n",
            "38   702.0  \n",
            "0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#df=pd.read_csv('/content/apple quality.csv',header=None)\n",
        "df=pd.read_csv('/content/ColonTumor.csv',header=None)\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "S1 = pd.DataFrame()\n",
        "k = 0\n",
        "a1 = 0\n",
        "acc1 = 0\n",
        "\n",
        "for i in range(10):\n",
        " h = mrmr_classif(X=X_train, y=y_train, K=1)\n",
        "\n",
        " S1[i]=X_train[h]\n",
        " X_train.drop(h, axis=1, inplace=True)\n",
        "\n",
        " rf = RandomForestClassifier(n_estimators=50,random_state=42)\n",
        " X_train_selected = S1\n",
        " X_test_selected = X_test[S1.columns]\n",
        " rf.fit(X_train_selected, y_train)\n",
        " y_pred1 = rf.predict(X_test_selected)\n",
        " a1 = accuracy_score(y_test, y_pred1)\n",
        " if i == 1 or a1 > acc1:\n",
        "      acc1 = a1\n",
        "      S_prime = S1\n",
        "'''rf.fit(S1, y_train)\n",
        " a1 = rf.score(S1, y_train)\n",
        " print(\"a1\", a1)'''\n",
        "'''y_pred = rf.predict(S1)\n",
        " a1 = (y_pred == y_train).mean()\n",
        " #accuracy = accuracy_score(y_train, y_pred)'''\n",
        "\n",
        "\n",
        "'''if i == 1 or a1 > acc1:\n",
        "      acc1 = a1\n",
        "      S_prime = S1'''\n",
        "print(S_prime)\n",
        "print(acc1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9JFD31y9vcL"
      },
      "source": [
        "# ***DFI***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdlXx3kJ9oAd",
        "outputId": "5a942dad-2ecd-4fa0-bb0b-2438816dd672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shap of each feature: [0.14554125 0.07915555 0.02806992 0.15874618 0.02732766 0.04298763\n",
            " 0.05108621 0.15872078 0.0526515  0.14945945]\n",
            "mic values:\n",
            "           0         1         2         3         4         5         6  \\\n",
            "0       NaN  0.786017  0.786907  0.689796  0.793088  0.617107  0.665645   \n",
            "1  0.786017       NaN  0.852937  0.618108    0.8196  0.837217  0.620112   \n",
            "2  0.786907  0.852937       NaN   0.56673  0.999673  0.754396  0.689796   \n",
            "3  0.689796  0.618108   0.56673       NaN  0.645864  0.704417  0.521158   \n",
            "4  0.793088    0.8196  0.999673  0.645864       NaN  0.718881  0.689796   \n",
            "5  0.617107  0.837217  0.754396  0.704417  0.718881       NaN  0.788631   \n",
            "6  0.665645  0.620112  0.689796  0.521158  0.689796  0.788631       NaN   \n",
            "7  0.574885  0.409245  0.419983  0.333316  0.406047  0.272352  0.395411   \n",
            "8  0.270951  0.370662  0.350045  0.311034  0.294411  0.379918  0.351964   \n",
            "9  0.439825   0.41051  0.389531  0.382478  0.374692  0.389271  0.322084   \n",
            "\n",
            "          7         8         9  \n",
            "0  0.574885  0.270951  0.439825  \n",
            "1  0.409245  0.370662   0.41051  \n",
            "2  0.419983  0.350045  0.389531  \n",
            "3  0.333316  0.311034  0.382478  \n",
            "4  0.406047  0.294411  0.374692  \n",
            "5  0.272352  0.379918  0.389271  \n",
            "6  0.395411  0.351964  0.322084  \n",
            "7       NaN   0.45404  0.607518  \n",
            "8   0.45404       NaN  0.485198  \n",
            "9  0.607518  0.485198       NaN  \n",
            "DFI of each feature is: [9.46758140e-06 2.32579663e-06 2.18234548e-09 1.15841236e-04\n",
            " 2.69594281e-09 3.18490440e-06 1.67853412e-05 8.63024809e-04\n",
            " 8.62053595e-04 9.73236247e-04]\n"
          ]
        }
      ],
      "source": [
        "def calculate_feature_importance(S_prime):\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(S_prime, y_train)\n",
        "    explainer = shap.TreeExplainer(rf_classifier)\n",
        "    shap_values = explainer.shap_values(S_prime)\n",
        "    #shap_values_array = np.array(shap_values)\n",
        "\n",
        "    #print(shap_values.shape)\n",
        "\n",
        "    f = np.sum(np.abs(shap_values), axis=0)\n",
        "    #print(f.shape)\n",
        "\n",
        "    avg = np.mean(f, axis=0)\n",
        "    #print(avg.shape)\n",
        "    return avg\n",
        "\n",
        "def calculate_MIC(S_prime):\n",
        "    mic_values = pd.DataFrame(index=S_prime.columns, columns=S_prime.columns)\n",
        "\n",
        "    for col1 in S_prime.columns:\n",
        "        for col2 in S_prime.columns:\n",
        "            if col1 != col2:\n",
        "                mine = MINE()\n",
        "                mine.compute_score(S1[col1], S1[col2])\n",
        "                mic_values.loc[col1, col2] = mine.mic()\n",
        "\n",
        "    return mic_values\n",
        "\n",
        "shapley = calculate_feature_importance(S_prime)\n",
        "mic_values = calculate_MIC(S_prime)\n",
        "\n",
        "def calculate_DFI(Shap, mic_values):\n",
        "    DFI = shapley.copy()\n",
        "    for col1 in S_prime.columns:\n",
        "        for col2 in S_prime.columns:\n",
        "            if col1 != col2:\n",
        "                DFI[col1] *= (1 - mic_values.loc[col1, col2])\n",
        "    return DFI\n",
        "DFI=calculate_DFI(shapley,mic_values)\n",
        "print(\"shap of each feature:\", shapley)\n",
        "print(\"mic values:\\n\", mic_values)\n",
        "print(\"DFI of each feature is:\", DFI)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DFI= pd.Series(DFI, dtype=float)\n"
      ],
      "metadata": {
        "id": "DIhrATC9tJx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ihI-096OjKh",
        "outputId": "ef8c37e5-a26f-4552-e671-fa00dcc75611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.000009', '0.000002', '0.000000', '0.000116', '0.000000', '0.000003', '0.000017', '0.000863', '0.000862', '0.000973']\n"
          ]
        }
      ],
      "source": [
        "decimal_values = [format(value, \".6f\") for value in DFI]\n",
        "print(decimal_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svHnitEhJthY",
        "outputId": "38e1db48-641d-4c07-eb53-bf5bd329d5fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5628926146127603e-250"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "max(DFI)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shapley)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euvBRXAmAbpP",
        "outputId": "58d43a04-ea98-4573-fcb8-b77929b99272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.14554125 0.07915555 0.02806992 0.15874618 0.02732766 0.04298763\n",
            " 0.05108621 0.15872078 0.0526515  0.14945945]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S=0\n",
        "def update_DFI(shap_values, mic_values, S_prime, S2):\n",
        "    #DFI =  # Initialize an empty dictionary to store DFI values\n",
        "\n",
        "    # Iterate over each feature in S1\n",
        "    for col_s1 in S_prime.columns:\n",
        "            DFI[col_s1] = shap_values[col_s1]\n",
        "            # Initialize a variable to store the product of (1 - MIC) values\n",
        "            product = 1.0\n",
        "            # Iterate over each feature in S2\n",
        "            for col_s2 in S2.columns:\n",
        "                # Calculate the product of (1 - MIC) values\n",
        "                product *= (1 - mic_values.loc[col_s1, col_s2])\n",
        "            # Update DFI for the current feature in S1\n",
        "            DFI[col_s1] = DFI[col_s1] *product\n",
        "    return pd.Series(DFI, index=S_prime.columns)\n",
        "\n",
        "S2 = pd.DataFrame()  # DataFrame to store selected features\n",
        "k = 0\n",
        "while k < 10 :\n",
        "    DFI = pd.Series(DFI, index=S_prime.columns)\n",
        "    # Select the feature with the largest DFI\n",
        "    selected_feature = DFI.idxmax()\n",
        "    # Add the selected feature to S2\n",
        "    S2[selected_feature] = S_prime[selected_feature]  # Add the selected feature to S2\n",
        "    S_prime.drop(selected_feature, axis=1, inplace=True)\n",
        "    DFI = update_DFI(shapley, mic_values, S_prime, S2)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    X_train_selected = S2\n",
        "    X_test_selected = X_test[S2.columns]\n",
        "    rf.fit(X_train_selected, y_train)\n",
        "    y_pred1 = rf.predict(X_test_selected)\n",
        "    a2 = accuracy_score(y_test, y_pred1)\n",
        "    #model.fit(S2, y_train)\n",
        "    #a2 = model.score(S2, y_train)\n",
        "    #y_pred = model.predict(S2)\n",
        "    #a2 = np.mean(y_pred == y_train)\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "    if a2 < acc1:\n",
        "      S2.drop(selected_feature, axis=1, inplace=True)\n",
        "    k += 1\n",
        "\n",
        "print(\"S2 is: \",S2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU4GeKThwLLb",
        "outputId": "ff3e68bd-1358-4b3c-a3b2-c650d78b7843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Selected feature 9, Accuracy: 0.625\n",
            "Iteration 2: Selected feature 3, Accuracy: 0.625\n",
            "Iteration 3: Selected feature 7, Accuracy: 0.625\n",
            "Iteration 4: Selected feature 0, Accuracy: 0.625\n",
            "Iteration 5: Selected feature 8, Accuracy: 0.625\n",
            "Iteration 6: Selected feature 6, Accuracy: 0.625\n",
            "Iteration 7: Selected feature 1, Accuracy: 0.3125\n",
            "Iteration 8: Selected feature 5, Accuracy: 0.625\n",
            "Iteration 9: Selected feature 4, Accuracy: 0.625\n",
            "Iteration 10: Selected feature 2, Accuracy: 0.625\n",
            "S2 is:           9       3      7       0       8       6       5       4       2\n",
            "3    233.0   338.0   95.2   138.0    43.3   442.0   334.0   196.0   209.0\n",
            "17   525.0   194.0   51.8   185.0   286.0    36.4    49.0   199.0   194.0\n",
            "48   374.0   481.0   83.9  1930.0   422.0  2640.0   992.0   645.0   558.0\n",
            "8    132.0   598.0   54.2  3890.0    28.9  1250.0   542.0  1730.0  1850.0\n",
            "6    148.0   387.0   77.2  2030.0    79.7   453.0   325.0  1470.0  1450.0\n",
            "33  1050.0   147.0  147.0   287.0   327.0    59.0    43.6   443.0   436.0\n",
            "4    371.0   661.0   36.3   988.0   393.0  1330.0   973.0   598.0   577.0\n",
            "46  1720.0   443.0  334.0   868.0  1280.0   584.0   103.0   606.0   453.0\n",
            "19   378.0   229.0  115.0   231.0   735.0    65.8    51.8   156.0   179.0\n",
            "53   734.0   217.0  115.0   660.0   835.0   608.0    76.7   393.0   393.0\n",
            "41   420.0    93.1   56.4   336.0   886.0   816.0   183.0   181.0   197.0\n",
            "54   184.0   581.0   13.7  3130.0   646.0  4070.0  1340.0  2310.0  2310.0\n",
            "31   948.0   261.0  323.0   471.0   380.0  1190.0   665.0   766.0   739.0\n",
            "30  2500.0   241.0  306.0   413.0   730.0   248.0   216.0   582.0   598.0\n",
            "58   313.0   115.0  117.0   175.0   834.0   690.0    88.6   127.0   134.0\n",
            "59  1040.0   239.0  102.0   966.0  2350.0   630.0    83.5   443.0   377.0\n",
            "15   242.0   450.0  116.0   636.0   456.0   421.0   282.0   660.0   633.0\n",
            "27   871.0   144.0  102.0   340.0   421.0   434.0   138.0   344.0   349.0\n",
            "26   672.0   103.0  110.0   103.0  1190.0   628.0    85.4   149.0   150.0\n",
            "24    49.8   229.0   13.0   164.0    48.8   108.0    69.1   209.0   213.0\n",
            "45   665.0  1050.0  134.0  2520.0   809.0  2900.0  1490.0  1780.0  1810.0\n",
            "11  1740.0   365.0  540.0   416.0   997.0   168.0    61.5   353.0   335.0\n",
            "32   623.0   176.0  278.0   813.0   190.0   230.0   111.0   562.0   663.0\n",
            "56   312.0   372.0   32.8  2790.0   182.0  2060.0   697.0  1890.0  1750.0\n",
            "44  2370.0   303.0  274.0   847.0  1180.0   673.0   228.0   736.0   541.0\n",
            "37   310.0   280.0  199.0   250.0   886.0   286.0   402.0   353.0   362.0\n",
            "29  1730.0   286.0  340.0   448.0  1520.0   474.0   413.0   448.0   474.0\n",
            "47   710.0   170.0  193.0   687.0  1740.0  1320.0    99.6   586.0   657.0\n",
            "1    510.0   624.0  137.0   553.0   631.0   561.0   309.0   471.0   475.0\n",
            "21   742.0   490.0  247.0   188.0  1170.0   105.0    81.3   246.0   272.0\n",
            "2    568.0  1340.0   78.2  2310.0   859.0  4420.0  1640.0  1710.0  1650.0\n",
            "50   371.0  1780.0   35.4  4640.0   311.0  3830.0  2200.0  2610.0  2570.0\n",
            "39   147.0   437.0   24.5  2690.0   228.0  3410.0  1210.0  1880.0  1720.0\n",
            "35   533.0   214.0  124.0   506.0   685.0   357.0   182.0   378.0   365.0\n",
            "23   298.0    79.3   16.2   182.0   409.0    91.5    16.0   133.0   118.0\n",
            "52  1800.0   357.0  146.0  1080.0   693.0   735.0    21.1   636.0   527.0\n",
            "10   131.0   906.0   51.2  4320.0   193.0  1770.0   774.0  2550.0  2510.0\n",
            "22   227.0  1270.0  107.0  2420.0   311.0  1850.0  1220.0  1770.0  1510.0\n",
            "18   139.0   620.0   45.5   412.0    83.9   127.0    89.8   378.0   373.0\n",
            "62   477.0   596.0   51.9  2700.0   129.0  1880.0   954.0  1160.0  1240.0\n",
            "20   146.0   760.0   57.8  3030.0    87.5   538.0   297.0  1510.0  1610.0\n",
            "7    610.0   150.0   99.3   228.0   402.0   144.0   126.0   199.0   215.0\n",
            "42   268.0   543.0   64.0  1770.0   439.0  1640.0   480.0  1290.0  1260.0\n",
            "14   157.0  1230.0   23.4  1870.0   236.0  1400.0  1240.0  1480.0  1420.0\n",
            "28  1360.0   255.0  241.0   330.0  1700.0   410.0   179.0   314.0   290.0\n",
            "51   649.0   361.0  118.0   754.0   400.0   252.0    55.2   195.0   212.0\n",
            "38   702.0    92.3   84.5   228.0   743.0    78.6    51.1   306.0   283.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if a2 < acc1 and k == 10:\n",
        "    S = S_prime\n",
        "else:\n",
        "    S = S2\n",
        "print(\"S is: \",S)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBmMvaUvMYc5",
        "outputId": "46f39a06-e8ed-40b5-9bfb-4c21b8f91aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S is:           9       3      7       0       8       6       5       4       2\n",
            "3    233.0   338.0   95.2   138.0    43.3   442.0   334.0   196.0   209.0\n",
            "17   525.0   194.0   51.8   185.0   286.0    36.4    49.0   199.0   194.0\n",
            "48   374.0   481.0   83.9  1930.0   422.0  2640.0   992.0   645.0   558.0\n",
            "8    132.0   598.0   54.2  3890.0    28.9  1250.0   542.0  1730.0  1850.0\n",
            "6    148.0   387.0   77.2  2030.0    79.7   453.0   325.0  1470.0  1450.0\n",
            "33  1050.0   147.0  147.0   287.0   327.0    59.0    43.6   443.0   436.0\n",
            "4    371.0   661.0   36.3   988.0   393.0  1330.0   973.0   598.0   577.0\n",
            "46  1720.0   443.0  334.0   868.0  1280.0   584.0   103.0   606.0   453.0\n",
            "19   378.0   229.0  115.0   231.0   735.0    65.8    51.8   156.0   179.0\n",
            "53   734.0   217.0  115.0   660.0   835.0   608.0    76.7   393.0   393.0\n",
            "41   420.0    93.1   56.4   336.0   886.0   816.0   183.0   181.0   197.0\n",
            "54   184.0   581.0   13.7  3130.0   646.0  4070.0  1340.0  2310.0  2310.0\n",
            "31   948.0   261.0  323.0   471.0   380.0  1190.0   665.0   766.0   739.0\n",
            "30  2500.0   241.0  306.0   413.0   730.0   248.0   216.0   582.0   598.0\n",
            "58   313.0   115.0  117.0   175.0   834.0   690.0    88.6   127.0   134.0\n",
            "59  1040.0   239.0  102.0   966.0  2350.0   630.0    83.5   443.0   377.0\n",
            "15   242.0   450.0  116.0   636.0   456.0   421.0   282.0   660.0   633.0\n",
            "27   871.0   144.0  102.0   340.0   421.0   434.0   138.0   344.0   349.0\n",
            "26   672.0   103.0  110.0   103.0  1190.0   628.0    85.4   149.0   150.0\n",
            "24    49.8   229.0   13.0   164.0    48.8   108.0    69.1   209.0   213.0\n",
            "45   665.0  1050.0  134.0  2520.0   809.0  2900.0  1490.0  1780.0  1810.0\n",
            "11  1740.0   365.0  540.0   416.0   997.0   168.0    61.5   353.0   335.0\n",
            "32   623.0   176.0  278.0   813.0   190.0   230.0   111.0   562.0   663.0\n",
            "56   312.0   372.0   32.8  2790.0   182.0  2060.0   697.0  1890.0  1750.0\n",
            "44  2370.0   303.0  274.0   847.0  1180.0   673.0   228.0   736.0   541.0\n",
            "37   310.0   280.0  199.0   250.0   886.0   286.0   402.0   353.0   362.0\n",
            "29  1730.0   286.0  340.0   448.0  1520.0   474.0   413.0   448.0   474.0\n",
            "47   710.0   170.0  193.0   687.0  1740.0  1320.0    99.6   586.0   657.0\n",
            "1    510.0   624.0  137.0   553.0   631.0   561.0   309.0   471.0   475.0\n",
            "21   742.0   490.0  247.0   188.0  1170.0   105.0    81.3   246.0   272.0\n",
            "2    568.0  1340.0   78.2  2310.0   859.0  4420.0  1640.0  1710.0  1650.0\n",
            "50   371.0  1780.0   35.4  4640.0   311.0  3830.0  2200.0  2610.0  2570.0\n",
            "39   147.0   437.0   24.5  2690.0   228.0  3410.0  1210.0  1880.0  1720.0\n",
            "35   533.0   214.0  124.0   506.0   685.0   357.0   182.0   378.0   365.0\n",
            "23   298.0    79.3   16.2   182.0   409.0    91.5    16.0   133.0   118.0\n",
            "52  1800.0   357.0  146.0  1080.0   693.0   735.0    21.1   636.0   527.0\n",
            "10   131.0   906.0   51.2  4320.0   193.0  1770.0   774.0  2550.0  2510.0\n",
            "22   227.0  1270.0  107.0  2420.0   311.0  1850.0  1220.0  1770.0  1510.0\n",
            "18   139.0   620.0   45.5   412.0    83.9   127.0    89.8   378.0   373.0\n",
            "62   477.0   596.0   51.9  2700.0   129.0  1880.0   954.0  1160.0  1240.0\n",
            "20   146.0   760.0   57.8  3030.0    87.5   538.0   297.0  1510.0  1610.0\n",
            "7    610.0   150.0   99.3   228.0   402.0   144.0   126.0   199.0   215.0\n",
            "42   268.0   543.0   64.0  1770.0   439.0  1640.0   480.0  1290.0  1260.0\n",
            "14   157.0  1230.0   23.4  1870.0   236.0  1400.0  1240.0  1480.0  1420.0\n",
            "28  1360.0   255.0  241.0   330.0  1700.0   410.0   179.0   314.0   290.0\n",
            "51   649.0   361.0  118.0   754.0   400.0   252.0    55.2   195.0   212.0\n",
            "38   702.0    92.3   84.5   228.0   743.0    78.6    51.1   306.0   283.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S=0\n",
        "'''def update_DFI(selected_feature, shap, mic_values, S1,DFI):\n",
        "    for col in S1.index:\n",
        "        if col != selected_feature:\n",
        "            DFI[col] *= (1 - mic_values.loc[col, selected_feature])\n",
        "\n",
        "    DFI[col] = shap[col] * np.prod(1 - mic_values.loc[col, selected_feature])\n",
        "\n",
        "   # DFI[selected_feature] = shap[selected_feature] * np.prod(1 - mic_values.loc[:, selected_feature])\n",
        "\n",
        "    return DFI'''\n",
        "def update_DFI(shap_values, mic_values, S1, S2):\n",
        "    #DFI =  # Initialize an empty dictionary to store DFI values\n",
        "\n",
        "    # Iterate over each feature in S1\n",
        "    for col_s1 in S1.columns:\n",
        "            DFI[col_s1] = shap_values[col_s1]\n",
        "            # Initialize a variable to store the product of (1 - MIC) values\n",
        "            product = 1.0\n",
        "            # Iterate over each feature in S2\n",
        "            for col_s2 in S2.columns:\n",
        "                # Calculate the product of (1 - MIC) values\n",
        "                product *= (1 - mic_values.loc[col_s1, col_s2])\n",
        "            # Update DFI for the current feature in S1\n",
        "            DFI[col_s1] = DFI[col_s1] *product\n",
        "    return pd.Series(DFI, index=S1.columns)\n",
        "\n",
        "\n",
        "S2 = pd.DataFrame()  # DataFrame to store selected features\n",
        "#DFI = pd.Series(av, index=S1.columns)  # Convert av to a pandas Series for compatibility\n",
        "a2 = 0\n",
        "#DFI = pd.Series(DFI, index=S1.columns)  # Initialize DFI with feature importances\n",
        "k = 0  # Initialize loop variable\n",
        "while k < 10 and a2 < acc1:\n",
        "    DFI = pd.Series(DFI, index=S1.columns)\n",
        "        # Select the feature with the largest DFI\n",
        "    selected_feature = DFI.idxmax()\n",
        "\n",
        "        # Add the selected feature to S2\n",
        "    '''S2 = pd.concat([S2, pd.DataFrame(S1[selected_feature])], axis=1)\n",
        "    #S2 = pd.concat([S2, pd.DataFrame(selected_feature)], axis=1)\n",
        "\n",
        "    if selected_feature in S1.columns:\n",
        "        selected_feature_data = S1[selected_feature]\n",
        "        S2 = pd.concat([S2, pd.DataFrame(selected_feature_data)], axis=1)\n",
        "        print(f\"Selected feature {selected_feature} added to S2.\")\n",
        "    else:\n",
        "        print(f\"Warning: {selected_feature} not found in S1 columns.\")'''\n",
        "        # Remove the selected feature from S1\n",
        "    '''S1.drop(selected_feature, axis=1, inplace=True)\n",
        "\n",
        "            # Update DFI of remaining features\n",
        "    DFI = update_DFI(shapley, mic_values, S1, S2)\n",
        "\n",
        "    # Reinitialize the model inside the loop\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    # Reset indices for both S2 and y_train\n",
        "    S2.reset_index(drop=True, inplace=True)\n",
        "    y_train_reset = y_train.reset_index(drop=True)\n",
        "\n",
        "    # Train a model with the updated feature set and calculate accuracy\n",
        "    model.fit(S2, y_train_reset)\n",
        "    #a2 = calculate_accuracy(model, S2, y_train_reset)\n",
        "    y_pred = model.predict(S2)\n",
        "    a2 = np.mean(y_pred == y_train)\n",
        "    # Record accuracy and update loop variables\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "    #print(DFI)\n",
        "    #k += 1\n",
        "\n",
        "    k += 1'''\n",
        "    S2[selected_feature] = S1[selected_feature]  # Add the selected feature to S2\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "    DFI = update_DFI(shapley, mic_values, S1, S2)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(S2, y_train)\n",
        "    accuracy = model.score(S2, y_train)\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {accuracy}\")\n",
        "    k += 1\n",
        "    if accuracy < acc1:\n",
        "        break\n",
        "\n",
        "    acc1 = accuracy\n",
        "print(S2)\n",
        "\n",
        "    #return S2, DFI\n",
        "#K = 10\n",
        "\n",
        "#selected_features, final_DFI = phase_2(S1.copy(), shapley, mic_values, y_train, K, acc1)\n",
        "\n",
        "if a2 < acc1 and k == 10:\n",
        "    S = S1\n",
        "else:\n",
        "    S = S2\n",
        "#print(S)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "_Ku_wwfBXG7b",
        "outputId": "eb0a251e-97a6-440c-f342-30eadcedd4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "attempt to get argmax of an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f278c73e7de8>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mDFI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDFI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Select the feature with the largest DFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mselected_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Add the selected feature to S2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0;31m# error: Argument 1 to \"argmax\" of \"IndexOpsMixin\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m         \u001b[0;31m# \"Union[int, Literal['index', 'columns']]\"; expected \"Optional[int]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;31m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# \"int\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             return nanops.nanargmax(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m    679\u001b[0m                 \u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanargmax\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;31m# error: Need type annotation for 'result'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[var-annotated]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def update_DFI(shap_values, mic_values, S1, S2):\n",
        "\n",
        "    # Iterate over each feature in S1\n",
        "    for col_s1 in S1.columns:\n",
        "        DFI[col_s1] = shap_values[col_s1]\n",
        "        # Initialize a variable to store the product of (1 - MIC) values\n",
        "        product = 1.0\n",
        "        # Iterate over each feature in S2\n",
        "        for col_s2 in S2.columns:\n",
        "            # Calculate the product of (1 - MIC) values\n",
        "            product *= (1 - mic_values.loc[col_s1, col_s2])\n",
        "        # Update DFI for the current feature in S1\n",
        "        DFI[col_s1] *= product\n",
        "\n",
        "    return pd.Series(DFI)\n",
        "\n",
        "\n",
        "S2 = pd.DataFrame()  # DataFrame to store selected features\n",
        "k = 0  # Initialize loop variable\n",
        "acc1 = 0  # Initialize acc1\n",
        "\n",
        "while k < 10 and acc1 < 0.9:\n",
        "    DFI = pd.Series(DFI,index=S1.columns)  # Initialize DFI with feature importances\n",
        "    selected_feature = DFI.idxmax()  # Select the feature with the largest DFI\n",
        "    S2[selected_feature] = S1[selected_feature]  # Add the selected feature to S2\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "    DFI = update_DFI(shapley, mic_values, S1, S2)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(S2, y_train)\n",
        "    accuracy = model.score(S2, y_train)\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {accuracy}\")\n",
        "    k += 1\n",
        "\n",
        "    if accuracy < acc1:\n",
        "        break\n",
        "\n",
        "    acc1 = accuracy\n",
        "\n",
        "print(S2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "322sLMCOqxJH",
        "outputId": "a4372a87-e805-45f3-be1b-1aaf2b650ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "reduction operation 'argmax' not allowed for this dtype",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-6a021d74e3ad>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0macc1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mDFI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDFI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize DFI with feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mselected_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Select the feature with the largest DFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mS2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Add the selected feature to S2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0;31m# error: Argument 1 to \"argmax\" of \"IndexOpsMixin\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m         \u001b[0;31m# \"Union[int, Literal['index', 'columns']]\"; expected \"Optional[int]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;31m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# \"int\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             return nanops.nanargmax(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m    679\u001b[0m                 \u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m     92\u001b[0m                     \u001b[0;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 )\n",
            "\u001b[0;31mTypeError\u001b[0m: reduction operation 'argmax' not allowed for this dtype"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def update_DFI(selected_feature, shap_values, mic_values, S1, S2):\n",
        "    DFI = {}  # Initialize an empty dictionary to store DFI values\n",
        "\n",
        "    # Iterate over each feature in S1\n",
        "    for col_s1 in S1:\n",
        "        if col_s1 != selected_feature:\n",
        "            DFI[col_s1] = shap_values[col_s1]\n",
        "            # Initialize a variable to store the product of (1 - MIC) values\n",
        "            product = 1.0\n",
        "            # Iterate over each feature in S2\n",
        "            for col_s2 in S2:\n",
        "                # Calculate the product of (1 - MIC) values\n",
        "                product *= (1 - mic_values.loc[col_s1, col_s2])\n",
        "            # Update DFI for the current feature in S1\n",
        "            DFI[col_s1] *= product\n",
        "\n",
        "    return DFI\n",
        "\n",
        "\n",
        "DFI = pd.Series(shapley)  # Initialize DFI with shapley values\n",
        "\n",
        "k = 0  # Initialize loop variable\n",
        "acc1 = 0.8  # Set the desired accuracy threshold\n",
        "a2 = 0  # Initialize accuracy variable\n",
        "\n",
        "while k < 10 and a2 < acc1:\n",
        "    # Select the feature with the largest DFI\n",
        "    selected_feature = DFI.idxmax()\n",
        "\n",
        "    # Add the selected feature to S2\n",
        "    if selected_feature in S1.columns:\n",
        "        selected_feature_data = S1[selected_feature]\n",
        "        S2 = pd.concat([S2, pd.DataFrame(selected_feature_data)], axis=1)\n",
        "        print(f\"Selected feature {selected_feature} added to S2.\")\n",
        "    else:\n",
        "        print(f\"Warning: {selected_feature} not found in S1 columns.\")\n",
        "\n",
        "    # Remove the selected feature from S1\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "\n",
        "    # Update DFI of remaining features\n",
        "    DFI = update_DFI(selected_feature, shapley, mic_values, S1, S2)\n",
        "\n",
        "    # Reinitialize the model inside the loop\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train a model with the updated feature set and calculate accuracy\n",
        "    model.fit(S2, y_train)\n",
        "    y_pred = model.predict(S2)\n",
        "    a2 = accuracy_score(y_train, y_pred)\n",
        "\n",
        "    # Record accuracy and update loop variables\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "\n",
        "    k += 1\n",
        "\n",
        "print(S2)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ybWN2_dK_5aE",
        "outputId": "2322d3f6-162d-451a-b528-dbe5d04c1616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 3 not found in S1 columns.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'[3] not found in axis'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8ed04939aac9>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Remove the selected feature from S1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Update DFI of remaining features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m         \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6935\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[3] not found in axis'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def update_DFI(selected_feature, shapley, mic_values, S1, S2):\n",
        "    DFI = {}  # Initialize an empty dictionary to store DFI values\n",
        "\n",
        "    # Iterate over each feature in S1\n",
        "    for col_s1 in S1:\n",
        "        if col_s1 != selected_feature:\n",
        "            DFI[col_s1] = shapley[col_s1]\n",
        "            # Initialize a variable to store the product of (1 - MIC) values\n",
        "            product = 1.0\n",
        "            # Iterate over each feature in S2\n",
        "            for col_s2 in S2:\n",
        "                # Calculate the product of (1 - MIC) values\n",
        "                product *= (1 - mic_values.loc[col_s1, col_s2])\n",
        "            # Update DFI for the current feature in S1\n",
        "            DFI[col_s1] *= product\n",
        "\n",
        "    return pd.Series(DFI)\n",
        "\n",
        "DFI = pd.Series(DFI, index=S1.columns)\n",
        "k = 0  # Initialize loop variable\n",
        "acc1 = 0.8  # Set the desired accuracy threshold\n",
        "a2 = 0  # Initialize accuracy variable\n",
        "\n",
        "while k < 10 and a2 < acc1:\n",
        "\n",
        "    # Select the feature with the largest DFI in S1\n",
        "    selected_feature = DFI.idxmax()\n",
        "\n",
        "    # Add the selected feature to S2\n",
        "    if selected_feature in S1.columns:\n",
        "        selected_feature_data = S1[selected_feature]\n",
        "        S2 = pd.concat([S2, pd.DataFrame(selected_feature_data)], axis=1)\n",
        "        print(f\"Selected feature {selected_feature} added to S2.\")\n",
        "    else:\n",
        "        print(f\"Warning: {selected_feature} not found in S1 columns.\")\n",
        "\n",
        "    # Remove the selected feature from S1\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "    DFI = update_DFI(None, shapley, mic_values, S1, S2)  # Update DFI values\n",
        "\n",
        "    # Reinitialize the model inside the loop\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    S2.reset_index(drop=True, inplace=True)\n",
        "    y_train_reset = y_train.reset_index(drop=True)\n",
        "    # Train a model with the updated feature set and calculate accuracy\n",
        "    model.fit(S2, y_train_reset)\n",
        "    y_pred = model.predict(S2)\n",
        "    a2 = np.mean(y_pred == y_train_reset)\n",
        "\n",
        "    # Record accuracy and update loop variables\n",
        "    #print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "    print(selected_feature)\n",
        "    print(a2)\n",
        "\n",
        "    k += 1\n",
        "\n",
        "print(S2)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ut8kh4QL60-e",
        "outputId": "b53495be-828e-4a65-989a-f9ca2a16da0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature 6 added to S2.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-470513be307b>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0my_train_reset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Train a model with the updated feature set and calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train_reset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected = S\n",
        "X_test_selected = X_test[S.columns]\n",
        "\n",
        "rf1 = RandomForestClassifier(n_estimators=50,random_state=42)\n",
        "rf1.fit(X_train_selected, y_train)\n",
        "\n",
        "y_pred1 = rf1.predict(X_test_selected)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(rf1, X_train_selected, y_train, cv=2)\n",
        "print('Mean Accuracy:', scores.mean())\n",
        "\n",
        "'''classification_rep = classification_report(y_test, y_pred1)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report using Random Forest Classifier:\")\n",
        "print(classification_rep)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "wKTYGg-6S7TN",
        "outputId": "9db0a854-2a25-4f34-abf9-88058ae176e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.8940217391304348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'classification_rep = classification_report(y_test, y_pred1)\\n\\nprint(f\"Accuracy: {accuracy:.4f}\")\\nprint(\"Classification Report using Random Forest Classifier:\")\\nprint(classification_rep)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-P0vo_b97vW"
      },
      "source": [
        "# ***Update DFI***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cFyoTMZ990IL",
        "outputId": "862ae896-0ebf-4f27-c4cc-4614f20f6c7d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (10) does not match length of index (9)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7fd7848021e7>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mDFI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize DFI with feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Initialize loop variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                 \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# create/copy the manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (10) does not match length of index (9)"
          ]
        }
      ],
      "source": [
        "'''def update_DFI(selected_feature, av, mic_values, DFI):\n",
        "    for col in DFI.index:\n",
        "        if col != selected_feature:\n",
        "            DFI[col] *= (1 - mic_values.loc[col, selected_feature])\n",
        "    DFI *= av[selected_feature]\n",
        "    return DFI'''\n",
        "def update_DFI(selected_feature, shapley, mic_values, DFI):\n",
        "    for col in DFI.index:\n",
        "        if col != selected_feature:\n",
        "            DFI[col] *= (1 - mic_values.loc[col, selected_feature])\n",
        "    DFI[col] = av[col] * np.prod(1 - mic_values.loc[col, selected_feature])\n",
        "    return DFI\n",
        "\n",
        "'''def calculate_accuracy(model, X_train, y_train):\n",
        "    y_pred = model.predict(X_train)\n",
        "    accuracy = np.mean(y_pred == y_train)\n",
        "    return accuracy'''\n",
        "\n",
        "S2 = pd.DataFrame()\n",
        "a2=0\n",
        "#DFI = pd.Series(shapley, index=S1.columns)\n",
        "k = 0\n",
        "\n",
        "#def phase_2(S1, shapley, mic_values, y_train, K, acc):\n",
        "\n",
        "S2 = pd.DataFrame()  # DataFrame to store selected features\n",
        "    #DFI = pd.Series(av, index=S1.columns)  # Convert av to a pandas Series for compatibility\n",
        "a2=0\n",
        "\n",
        "DFI = pd.Series(av, index=S1.columns)  # Initialize DFI with feature importances\n",
        "\n",
        "k = 0  # Initialize loop variable\n",
        "\n",
        "\n",
        "while k < 10 and a2 < acc1:  # Use K instead of k\n",
        "        # Select the feature with the largest DFI\n",
        "    selected_feature = DFI.idxmax()\n",
        "    print(selected_feature)\n",
        "        # Add the selected feature to S2\n",
        "    S2 = pd.concat([S2, pd.DataFrame(S1[selected_feature])], axis=1)\n",
        "    print(S2)\n",
        "       # print(\"S2\", S2)\n",
        "        # Remove the selected feature from S1\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "\n",
        "        # Update DFI of remaining features\n",
        "    DFI = update_DFI(selected_feature, shapley, mic_values, DFI)\n",
        "\n",
        "        # Reinitialize the model inside the loop\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "        # Reset indices for both S2 and y_train\n",
        "    S2.reset_index(drop=True, inplace=True)\n",
        "    y_train_reset = y_train.reset_index(drop=True)\n",
        "\n",
        "        # Train a model with the updated feature set and calculate accuracy\n",
        "    model.fit(S2, y_train_reset)\n",
        "        #a2 = calculate_accuracy(model, S2, y_train_reset)\n",
        "    y_pred = model.predict(S2)\n",
        "    a2 = np.mean(y_pred == y_train)\n",
        "\n",
        "        # Record accuracy and update loop variables\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "    k += 1\n",
        "\n",
        "      #return S2, DFI\n",
        "#K=10\n",
        "#selected_features, final_DFI = phase_2(S1.copy(), shapley, mic_values, y_train, K, acc1)\n",
        "\n",
        "'''if a2 < acc1 and k == K:\n",
        "    selected_features = S1\n",
        "else:\n",
        "    selected_features = S2\n",
        "\n",
        "print(\"\\nSelected Features:\")\n",
        "print(selected_features)'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import shap\n",
        "from minepy import MINE\n",
        "\n",
        "# Function to calculate feature importance using Shapley values\n",
        "def calculate_feature_importance(S1):\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(S1, y_train)\n",
        "    explainer = shap.Explainer(rf_classifier)\n",
        "    shap_values = explainer.shap_values(S1)\n",
        "    f = np.sum(np.abs(shap_values), axis=0)\n",
        "    av = np.mean(f, axis=0)\n",
        "    return av\n",
        "\n",
        "# Function to calculate MIC values between features\n",
        "def calculate_MIC(S1):\n",
        "    mic_values = pd.DataFrame(index=S1.columns, columns=S1.columns)\n",
        "\n",
        "    for col1 in S1.columns:\n",
        "        for col2 in S1.columns:\n",
        "            if col1 != col2:\n",
        "                mine = MINE()\n",
        "                mine.compute_score(S1[col1], S1[col2])\n",
        "                mic_values.loc[col1, col2] = mine.mic()\n",
        "\n",
        "    return mic_values\n",
        "\n",
        "# Function to update DFI values for the remaining features\n",
        "def update_DFI(selected_feature, av, mic_values, DFI):\n",
        "    for col in DFI.index:\n",
        "        if col != selected_feature:\n",
        "            # Update based on MIC values with respect to selected_feature\n",
        "            DFI[col] *= (1 - mic_values.loc[col, selected_feature])\n",
        "    # Update DFI for the selected feature\n",
        "    DFI[selected_feature] = av[selected_feature] * np.prod(1 - mic_values.loc[selected_feature, DFI.index])\n",
        "    return DFI\n",
        "\n",
        "# Function to perform the feature selection process\n",
        "def feature_selection(S1, y_train, K):\n",
        "    S2 = pd.DataFrame()  # DataFrame to store selected features\n",
        "    av = calculate_feature_importance(S1)\n",
        "    mic_values = calculate_MIC(S1)\n",
        "    DFI = pd.Series(av, index=S1.columns)  # Initialize DFI with feature importances\n",
        "    k = 0  # Initialize loop variable\n",
        "\n",
        "    while k < K:\n",
        "        # Select the feature with the highest DFI\n",
        "        selected_feature = DFI.idxmax()\n",
        "\n",
        "        # Add the selected feature to S2\n",
        "        S2 = pd.concat([S2, pd.DataFrame(S1[selected_feature])], axis=1)\n",
        "\n",
        "        # Remove the selected feature from S1\n",
        "        S1.drop(selected_feature, axis=1, inplace=True)\n",
        "\n",
        "        # Update DFI of remaining features\n",
        "        DFI = update_DFI(selected_feature, av, mic_values, DFI)\n",
        "\n",
        "        # Reinitialize the model inside the loop\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "        # Reset indices for both S2 and y_train\n",
        "        S2.reset_index(drop=True, inplace=True)\n",
        "        y_train_reset = y_train.reset_index(drop=True)\n",
        "\n",
        "        # Train a model with the updated feature set and calculate accuracy\n",
        "        model.fit(S2, y_train_reset)\n",
        "        y_pred = model.predict(S2)\n",
        "        a2 = np.mean(y_pred == y_train)\n",
        "\n",
        "        # Record accuracy and update loop variables\n",
        "        print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {a2}\")\n",
        "        k += 1\n",
        "\n",
        "    return S2\n",
        "\n",
        "# Example usage\n",
        "K = 3  # Number of iterations\n",
        "y_train = pd.Series([0, 1, 0, 1, 1, 0, 1, 0, 1, 0])  # Replace this with your actual y_train\n",
        "S1 = pd.DataFrame(np.random.rand(10, 5), columns=['f1', 'f2', 'f3', 'f4', 'f5'])  # Replace this with your actual S1\n",
        "\n",
        "selected_features = feature_selection(S1.copy(), y_train, K)\n",
        "print(\"Selected Features:\", selected_features.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "FXR8vm7Nw-hY",
        "outputId": "429e7485-476a-4470-948d-d95ae577381f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fd78e5bcd18c>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace this with your actual S1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected Features:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-fd78e5bcd18c>\u001b[0m in \u001b[0;36mfeature_selection\u001b[0;34m(S1, y_train, K)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Update DFI of remaining features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mDFI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_DFI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmic_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Reinitialize the model inside the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-fd78e5bcd18c>\u001b[0m in \u001b[0;36mupdate_DFI\u001b[0;34m(selected_feature, av, mic_values, DFI)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mDFI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmic_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Update DFI for the selected feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mDFI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmic_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_-i-4ywA_NLR",
        "outputId": "d2bc996e-961c-4c43-a311-6dcc9d38d10c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'selected_feature' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bcf2198aa63f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'selected_feature' is not defined"
          ]
        }
      ],
      "source": [
        "X_train_selected = selected_feature\n",
        "X_test_selected = X_test[selected_feature.columns]\n",
        "\n",
        "rf1 = RandomForestClassifier(n_estimators=50,random_state=42)\n",
        "rf1.fit(X_train_selected, y_train)\n",
        "\n",
        "y_pred1 = rf1.predict(X_test_selected)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(rf1, X_train_selected, y_train, cv=2)\n",
        "print('Mean Accuracy:', scores.mean())\n",
        "\n",
        "classification_rep = classification_report(y_test, y_pred1)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report using Random Forest Classifier:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "BGsgrRjxHd9W",
        "outputId": "b41e0ed7-900a-4ee6-f1dd-a2ed707ad203"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7664e446300a>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Calculate DFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mDFI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_DFI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmic_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Select the feature with the highest DFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-7664e446300a>\u001b[0m in \u001b[0;36mcalculate_DFI\u001b[0;34m(S1, av, mic_values)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcol1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mDFI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmic_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from minepy import MINE\n",
        "import shap\n",
        "\n",
        "# Function to calculate feature importance using Shapley values\n",
        "def calculate_feature_importance(S1, y_train):\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(S1, y_train)\n",
        "\n",
        "    explainer = shap.Explainer(rf_classifier)\n",
        "    shap_values = explainer.shap_values(S1)\n",
        "    f = np.sum(np.abs(shap_values), axis=0)\n",
        "    av = np.mean(f, axis=0)\n",
        "    return av\n",
        "\n",
        "# Function to calculate MIC values\n",
        "def calculate_MIC(S1):\n",
        "    mic_values = pd.DataFrame(index=S1.columns, columns=S1.columns)\n",
        "\n",
        "    for col1 in S1.columns:\n",
        "        for col2 in S1.columns:\n",
        "            if col1 != col2:\n",
        "                mine = MINE()\n",
        "                mine.compute_score(S1[col1], S1[col2])\n",
        "                mic_values.loc[col1, col2] = mine.mic()\n",
        "\n",
        "    return mic_values\n",
        "\n",
        "# Function to calculate DFI (Shapley * Product of (1 - MIC))\n",
        "def calculate_DFI(S1, av, mic_values):\n",
        "    DFI = av.copy()\n",
        "    for col1 in S1.columns:\n",
        "        for col2 in S1.columns:\n",
        "            if col1 != col2:\n",
        "                DFI[col1] *= (1 - mic_values.loc[col1, col2])\n",
        "\n",
        "    return DFI\n",
        "\n",
        "# Function to update DFI based on the selected feature in S2\n",
        "def update_DFI(selected_feature, DFI, av, mic_values):\n",
        "    for col in DFI.index:\n",
        "        if col != selected_feature:\n",
        "            DFI[col] *= (1 - mic_values.loc[col, selected_feature])\n",
        "    DFI *= av  # Update DFI using the feature importance (shap values)\n",
        "\n",
        "    return DFI\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = np.mean(y_pred == y)\n",
        "    return accuracy\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'f1': [1, 2, 3, 4, 5],\n",
        "    'f2': [2, 3, 4, 5, 6],\n",
        "    'f3': [3, 4, 5, 6, 7],\n",
        "    'f4': [4, 5, 6, 7, 8],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "y_train = pd.Series([0, 1, 0, 1, 0])\n",
        "\n",
        "# Initialize S2 and DFI\n",
        "S1 = df.copy()\n",
        "S2 = pd.DataFrame()\n",
        "DFI = pd.Series(index=df.columns)\n",
        "\n",
        "# Set the desired number of iterations\n",
        "K = 2\n",
        "\n",
        "# Initialize loop variables\n",
        "k = 0\n",
        "acc1 = 0\n",
        "\n",
        "while k < K:\n",
        "    # Calculate feature importance using Shapley values\n",
        "    av = calculate_feature_importance(S1, y_train)\n",
        "\n",
        "    # Calculate MIC values\n",
        "    mic_values = calculate_MIC(S1)\n",
        "\n",
        "    # Calculate DFI\n",
        "    DFI = calculate_DFI(S1, av, mic_values)\n",
        "\n",
        "    # Select the feature with the highest DFI\n",
        "    selected_feature = DFI.idxmax()\n",
        "\n",
        "    # Add the selected feature to S2\n",
        "    S2[selected_feature] = S1[selected_feature]\n",
        "\n",
        "    # Remove the selected feature from S1\n",
        "    S1.drop(selected_feature, axis=1, inplace=True)\n",
        "\n",
        "    # Update DFI of remaining features\n",
        "    DFI = update_DFI(selected_feature, DFI, av, mic_values)\n",
        "\n",
        "    # Reinitialize the model inside the loop\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train a model with the updated feature set and calculate accuracy\n",
        "    model.fit(S2, y_train)\n",
        "    accuracy = calculate_accuracy(model, S2, y_train)\n",
        "\n",
        "    print(f\"Iteration {k + 1}: Selected feature {selected_feature}, Accuracy: {accuracy}\")\n",
        "\n",
        "    if accuracy < acc1:\n",
        "        break\n",
        "\n",
        "    k += 1\n",
        "\n",
        "# Check if S2 or S1' should be selected based on accuracy\n",
        "if accuracy < acc1 and k == K:\n",
        "    selected_features = S1\n",
        "else:\n",
        "    selected_features = S2\n",
        "\n",
        "print(\"\\nSelected Features:\")\n",
        "print(selected_features)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}